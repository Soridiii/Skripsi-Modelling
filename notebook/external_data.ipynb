{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b25af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b236a1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text    Label\n",
       "0     im feeling rather rotten so im not very ambiti...  sadness\n",
       "1             im updating my blog because i feel shitty  sadness\n",
       "2     i never make her separate from me because i do...  sadness\n",
       "3     i left with my bouquet of red and yellow tulip...      joy\n",
       "4       i was feeling a little vain when i did this one  sadness\n",
       "...                                                 ...      ...\n",
       "1995  i just keep feeling like someone is being unki...    anger\n",
       "1996  im feeling a little cranky negative after this...    anger\n",
       "1997  i feel that i am useful to my people and that ...      joy\n",
       "1998  im feeling more comfortable with derby i feel ...      joy\n",
       "1999  i feel all weird when i have to meet w people ...     fear\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"../data/dataset/test.txt\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, delimiter='\\\\;', header=None,\n",
    "                 names=['Text', 'Label'], engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40ff4c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "joy         695\n",
      "sadness     581\n",
      "anger       275\n",
      "fear        224\n",
      "love        159\n",
      "surprise     66\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e1439c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Gembira    695\n",
      "Sedih      581\n",
      "Marah      275\n",
      "Takut      224\n",
      "Cinta      159\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mengubag nama label menjadi bahasa Indonesia\n",
    "label_mapping = {\n",
    "    'joy': 'Gembira',\n",
    "    'sadness': 'Sedih',\n",
    "    'fear': 'Takut',\n",
    "    'anger': 'Marah',\n",
    "    'love': 'Cinta',\n",
    "}\n",
    "df['Label'] = df['Label'].map(label_mapping)\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51e2f72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna(subset=['Text'])\n",
    "df_cleaned = df_cleaned.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b71394c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 9a0d4d81-45b2-4a8e-ac2b-7232a71302ca)')' thrown while requesting HEAD https://huggingface.co/facebook/nllb-200-distilled-600M/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\n",
    "    \"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    src_lang=\"eng_Latn\",\n",
    "    tgt_lang=\"ind_Latn\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6b620d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_translate(text):\n",
    "    if pd.isna(text) or not str(text).strip():\n",
    "        return text\n",
    "    result = translator(str(text), max_length=400)\n",
    "    return result[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68136a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai terjemahan...\n"
     ]
    }
   ],
   "source": [
    "print(\"Memulai terjemahan...\")\n",
    "df_translated = df_cleaned\n",
    "df_translated['Text_ID'] = df_translated['Text'].apply(simple_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "848c9ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>Sedih</td>\n",
       "      <td>Aku merasa agak busuk jadi aku tidak terlalu a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>Sedih</td>\n",
       "      <td>Aku memperbarui blogku karena aku merasa buruk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>Sedih</td>\n",
       "      <td>Aku tak pernah memisahkannya dariku karena aku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>Gembira</td>\n",
       "      <td>Saya pergi dengan buket tulip merah dan kuning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>Sedih</td>\n",
       "      <td>Aku merasa sedikit sia-sia ketika aku melakuka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>Marah</td>\n",
       "      <td>Aku hanya terus merasa seperti seseorang tidak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>Marah</td>\n",
       "      <td>Aku merasa sedikit cranky negatif setelah janj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>Gembira</td>\n",
       "      <td>Saya merasa bahwa saya berguna bagi orang-oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>Gembira</td>\n",
       "      <td>Aku merasa lebih nyaman dengan Derby Aku meras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>Takut</td>\n",
       "      <td>Aku merasa aneh ketika aku harus bertemu denga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text    Label  \\\n",
       "0     im feeling rather rotten so im not very ambiti...    Sedih   \n",
       "1             im updating my blog because i feel shitty    Sedih   \n",
       "2     i never make her separate from me because i do...    Sedih   \n",
       "3     i left with my bouquet of red and yellow tulip...  Gembira   \n",
       "4       i was feeling a little vain when i did this one    Sedih   \n",
       "...                                                 ...      ...   \n",
       "1995  i just keep feeling like someone is being unki...    Marah   \n",
       "1996  im feeling a little cranky negative after this...    Marah   \n",
       "1997  i feel that i am useful to my people and that ...  Gembira   \n",
       "1998  im feeling more comfortable with derby i feel ...  Gembira   \n",
       "1999  i feel all weird when i have to meet w people ...    Takut   \n",
       "\n",
       "                                                Text_ID  \n",
       "0     Aku merasa agak busuk jadi aku tidak terlalu a...  \n",
       "1        Aku memperbarui blogku karena aku merasa buruk  \n",
       "2     Aku tak pernah memisahkannya dariku karena aku...  \n",
       "3     Saya pergi dengan buket tulip merah dan kuning...  \n",
       "4     Aku merasa sedikit sia-sia ketika aku melakuka...  \n",
       "...                                                 ...  \n",
       "1995  Aku hanya terus merasa seperti seseorang tidak...  \n",
       "1996  Aku merasa sedikit cranky negatif setelah janj...  \n",
       "1997  Saya merasa bahwa saya berguna bagi orang-oran...  \n",
       "1998  Aku merasa lebih nyaman dengan Derby Aku meras...  \n",
       "1999  Aku merasa aneh ketika aku harus bertemu denga...  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e965508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "from indoNLP.preprocessing import replace_word_elongation, replace_slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a294bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1305 entries from kamus.csv\n"
     ]
    }
   ],
   "source": [
    "def cleanDataframe(df):\n",
    "    print('Missing Values:', df.isnull().sum())\n",
    "    print('Duplicates:', df.duplicated().sum())\n",
    "\n",
    "    df_cleaned = df.dropna()\n",
    "    df_cleaned = df_cleaned.drop_duplicates(keep='first')\n",
    "\n",
    "    print('\\nMissing values after cleaning:', df_cleaned.isnull().sum())\n",
    "    print('Duplicates after cleaning:', df_cleaned.duplicated().sum())\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def cleaningText(text):\n",
    "    # Membersihkan tanda tanda sisa medsos\n",
    "    text = re.sub(r'\\[USERNAME\\]', '', text)\n",
    "    text = re.sub(r'\\[URL\\]', '', text)\n",
    "    text = re.sub(r'\\[SENSITIVE-NO\\]', '', text)\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Menghapus Mention\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text)  # Menghapus Hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text)  # menghapus RT\n",
    "    text = re.sub(r\"http\\S+\", '', text)  # menghapus link\n",
    "\n",
    "    # Pembersihan Karakter\n",
    "    # Mengganti tanda baca dengan spasi (alih-alih menghapus)\n",
    "    text = text.translate(str.maketrans(\n",
    "        string.punctuation, ' ' * len(string.punctuation)))\n",
    "    text = re.sub(r'\\d+', '', text)  # Menghapus angka\n",
    "    text = text.replace('\\n', ' ')  # Mengganti garis baru dengan spasi\n",
    "    return text\n",
    "\n",
    "\n",
    "kamusCleaning = pd.read_csv('../data/kamus.csv', encoding='utf-8',\n",
    "                            delimiter=',', header=None, names=['slang', 'formal'])\n",
    "\n",
    "\n",
    "cleaningDict = {}\n",
    "for slang, formal in zip(kamusCleaning.slang, kamusCleaning.formal):\n",
    "    if pd.notna(slang) and pd.notna(formal):\n",
    "        slang_lower = str(slang).lower().strip()\n",
    "        formal_clean = str(formal).strip()\n",
    "        cleaningDict[slang_lower] = formal_clean\n",
    "\n",
    "print(f\"✅ Loaded {len(cleaningDict)} entries from kamus.csv\")\n",
    "\n",
    "\n",
    "def applyCleaningDict(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return text\n",
    "\n",
    "    # Pattern untuk match whole words (case insensitive)\n",
    "    words = text.split()\n",
    "    cleaned_words = []\n",
    "\n",
    "    for word in words:\n",
    "        # Clean word (lowercase untuk matching)\n",
    "        clean_word = word.lower().strip()\n",
    "\n",
    "        # Check jika word ada di dictionary\n",
    "        if clean_word in cleaningDict:\n",
    "            cleaned_words.append(cleaningDict[clean_word])\n",
    "        else:\n",
    "            cleaned_words.append(word)\n",
    "\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def normalizeText(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    if not text.strip():\n",
    "        return text.strip()\n",
    "\n",
    "    # 1. Lowercase pertama\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Handle character elongation\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "    if 'replace_word_elongation' in globals():\n",
    "        text = replace_word_elongation(text)\n",
    "\n",
    "    # 3. Replace slang words (dari multiple sources)\n",
    "    if 'replace_slang' in globals():\n",
    "        text = replace_slang(text)\n",
    "    text = applyCleaningDict(text)\n",
    "\n",
    "    # 4. Final cleanup\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d36cc416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values: Label      66\n",
      "Text_ID     0\n",
      "dtype: int64\n",
      "Duplicates: 2\n",
      "\n",
      "Missing values after cleaning: Label      0\n",
      "Text_ID    0\n",
      "dtype: int64\n",
      "Duplicates after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "df_final = df_translated[['Label', 'Text_ID']]\n",
    "df_final = cleanDataframe(df_final)\n",
    "df_final['Text_ID'] = df_final['Text_ID'].apply(cleaningText)\n",
    "df_normalized = df_final.copy()\n",
    "df_normalized['Text_ID'] = df_normalized['Text_ID'].apply(normalizeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b09610ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Gembira    695\n",
       "Sedih      580\n",
       "Marah      275\n",
       "Takut      223\n",
       "Cinta      159\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ecb1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df by label\n",
    "df_normalized = df_normalized.sort_values(by='Label').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.to_csv('../data/external_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
