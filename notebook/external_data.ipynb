{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b25af73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping line 2731: []\n",
      "Shape: (2730, 2)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"../data/raw_data/test_dataset.csv\"\n",
    "\n",
    "data = []\n",
    "with open(DATA_PATH, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file, quotechar='\"', escapechar='\\\\')\n",
    "    for i, row in enumerate(reader):\n",
    "        if len(row) == 2:\n",
    "            data.append(row)\n",
    "        elif len(row) > 2:\n",
    "            # Gabungkan field tambahan ke tweet\n",
    "            label = row[0]\n",
    "            tweet = ','.join(row[1:])\n",
    "            data.append([label, tweet])\n",
    "        else:\n",
    "            print(f\"Skipping line {i}: {row}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "if data:\n",
    "    df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    df.head()\n",
    "else:\n",
    "    print(\"No data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a597e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'label': 'Label', 'teks':'Tweet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7af91f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marah</td>\n",
       "      <td>Gue benar-benar jengkel sama orang-orang yang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marah</td>\n",
       "      <td>Dasar pemerintah bangsat, urusan rakyat kecil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marah</td>\n",
       "      <td>Aku benci banget sama diriku sendiri yang sela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marah</td>\n",
       "      <td>Anjir, nyebelin banget dah aplikasi gojek lagi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marah</td>\n",
       "      <td>Gue muak sama berita-berita hoax yang bikin re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>Sedih</td>\n",
       "      <td>rasanya kaya hati gue tertutup kabut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>Sedih</td>\n",
       "      <td>gue sedih tiap denger suara yang dulu hangat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>Sedih</td>\n",
       "      <td>gue ngerasa ga ada yang ngerti perasaan gue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>Sedih</td>\n",
       "      <td>rasanya seperti luka yang tak kunjung sembuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>Sedih</td>\n",
       "      <td>gue sedih karena kehilangan kepercayaan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2730 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                              Tweet\n",
       "0     Marah  Gue benar-benar jengkel sama orang-orang yang ...\n",
       "1     Marah  Dasar pemerintah bangsat, urusan rakyat kecil ...\n",
       "2     Marah  Aku benci banget sama diriku sendiri yang sela...\n",
       "3     Marah  Anjir, nyebelin banget dah aplikasi gojek lagi...\n",
       "4     Marah  Gue muak sama berita-berita hoax yang bikin re...\n",
       "...     ...                                                ...\n",
       "2725  Sedih               rasanya kaya hati gue tertutup kabut\n",
       "2726  Sedih       gue sedih tiap denger suara yang dulu hangat\n",
       "2727  Sedih        gue ngerasa ga ada yang ngerti perasaan gue\n",
       "2728  Sedih       rasanya seperti luka yang tak kunjung sembuh\n",
       "2729  Sedih            gue sedih karena kehilangan kepercayaan\n",
       "\n",
       "[2730 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e1439c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Gembira    1095\n",
      "Marah       470\n",
      "Takut       424\n",
      "Cinta       400\n",
      "Sedih       341\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mengubag nama label menjadi bahasa Indonesia\n",
    "label_mapping = {\n",
    "    'Senang': 'Gembira',\n",
    "    'Cinta': 'Cinta',\n",
    "    'Takut': 'Takut',\n",
    "    'Sedih': 'Sedih',\n",
    "    'Marah': 'Marah'\n",
    "}\n",
    "df['Label'] = df['Label'].map(label_mapping)\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2f72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6de18a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Gembira    1095\n",
      "Marah       470\n",
      "Takut       424\n",
      "Cinta       400\n",
      "Sedih       341\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e1be58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.str.contains('final_text')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6cbc619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "Gembira    1095\n",
      "Marah       470\n",
      "Takut       424\n",
      "Cinta       400\n",
      "Sedih       341\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#remove surprise label from dataset\n",
    "df = df[df['Label'] != 'surprise'].copy()\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f16a95a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cinta</td>\n",
       "      <td>rasanya kaya hati gue dikenyalkan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cinta</td>\n",
       "      <td>tadi gue ngerasa semua jadi lebih adem karena dia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cinta</td>\n",
       "      <td>gue rindu hal sederhana yang dia lakukan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cinta</td>\n",
       "      <td>gue suka tiap dia ngomong dengan pelan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cinta</td>\n",
       "      <td>rasanya kaya gue ditutupin selimut hangat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                              Tweet\n",
       "0  Cinta                  rasanya kaya hati gue dikenyalkan\n",
       "1  Cinta  tadi gue ngerasa semua jadi lebih adem karena dia\n",
       "2  Cinta           gue rindu hal sederhana yang dia lakukan\n",
       "3  Cinta             gue suka tiap dia ngomong dengan pelan\n",
       "4  Cinta          rasanya kaya gue ditutupin selimut hangat"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort df by label\n",
    "df = df.sort_values(by='Label').reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17bd68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./data/external_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897b9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3f261dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi Label Setelah Downsampling:\n",
      "Label\n",
      "Gembira    473\n",
      "Marah      470\n",
      "Takut      424\n",
      "Cinta      400\n",
      "Sedih      341\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77207/4123522497.py:8: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N_SAMPLES = 473\n",
    "LABEL = 'Label'\n",
    "\n",
    "df_downsampled = (\n",
    "    df.groupby(LABEL)\n",
    "    .apply(lambda x: x.sample(\n",
    "        n=min(len(x), N_SAMPLES),\n",
    "        random_state=42\n",
    "    ))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Distribusi Label Setelah Downsampling:\")\n",
    "print(df_downsampled[LABEL].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78bc4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop final_text column\n",
    "df = df_downsampled.loc[:, ~df.columns.str.contains('final_text')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4ed76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "from indoNLP.preprocessing import replace_word_elongation, replace_slang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e504cac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1305 entries from kamus.csv\n"
     ]
    }
   ],
   "source": [
    "def cleanDataframe(df):\n",
    "    print('Missing Values:', df.isnull().sum())\n",
    "    print('Duplicates:', df.duplicated().sum())\n",
    "\n",
    "    df_cleaned = df.dropna(subset='Tweet')\n",
    "    df_cleaned = df_cleaned.drop_duplicates(keep='first')\n",
    "\n",
    "    print('\\nMissing values after cleaning:', df_cleaned.isnull().sum())\n",
    "    print('Duplicates after cleaning:', df_cleaned.duplicated().sum())\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "def cleaningText(text):\n",
    "    # Membersihkan tanda tanda sisa medsos\n",
    "    text = re.sub(r'\\[USERNAME\\]', '', text)\n",
    "    text = re.sub(r'\\[URL\\]', '', text)\n",
    "    text = re.sub(r'\\[SENSITIVE-NO\\]', '', text)\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Menghapus Mention\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text)  # Menghapus Hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text)  # menghapus RT\n",
    "    text = re.sub(r\"http\\S+\", '', text)  # menghapus link\n",
    "\n",
    "    # Pembersihan Karakter\n",
    "    # Mengganti tanda baca dengan spasi (alih-alih menghapus)\n",
    "    text = text.translate(str.maketrans(\n",
    "        string.punctuation, ' ' * len(string.punctuation)))\n",
    "    text = re.sub(r'\\d+', '', text)  # Menghapus angka\n",
    "    text = text.replace('\\n', ' ')  # Mengganti garis baru dengan spasi\n",
    "    return text\n",
    "\n",
    "\n",
    "kamusCleaning = pd.read_csv('../data/kamus.csv', encoding='utf-8',\n",
    "                            delimiter=',', header=None, names=['slang', 'formal'])\n",
    "\n",
    "\n",
    "cleaningDict = {}\n",
    "for slang, formal in zip(kamusCleaning.slang, kamusCleaning.formal):\n",
    "    if pd.notna(slang) and pd.notna(formal):\n",
    "        slang_lower = str(slang).lower().strip()\n",
    "        formal_clean = str(formal).strip()\n",
    "        cleaningDict[slang_lower] = formal_clean\n",
    "\n",
    "print(f\"✅ Loaded {len(cleaningDict)} entries from kamus.csv\")\n",
    "\n",
    "\n",
    "def applyCleaningDict(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return text\n",
    "\n",
    "    # Pattern untuk match whole words (case insensitive)\n",
    "    words = text.split()\n",
    "    cleaned_words = []\n",
    "\n",
    "    for word in words:\n",
    "        # Clean word (lowercase untuk matching)\n",
    "        clean_word = word.lower().strip()\n",
    "\n",
    "        # Check jika word ada di dictionary\n",
    "        if clean_word in cleaningDict:\n",
    "            cleaned_words.append(cleaningDict[clean_word])\n",
    "        else:\n",
    "            cleaned_words.append(word)\n",
    "\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def normalizeText(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    if not text.strip():\n",
    "        return text.strip()\n",
    "\n",
    "    # 1. Lowercase pertama\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Handle character elongation\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "    if 'replace_word_elongation' in globals():\n",
    "        text = replace_word_elongation(text)\n",
    "\n",
    "    # 3. Replace slang words (dari multiple sources)\n",
    "    if 'replace_slang' in globals():\n",
    "        text = replace_slang(text)\n",
    "    text = applyCleaningDict(text)\n",
    "\n",
    "    # 4. Final cleanup\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "96b32cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values: Label    0\n",
      "Tweet    0\n",
      "dtype: int64\n",
      "Duplicates: 158\n",
      "\n",
      "Missing values after cleaning: Label    0\n",
      "Tweet    0\n",
      "dtype: int64\n",
      "Duplicates after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = cleanDataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55b7772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet'] = df['Tweet'].apply(cleaningText)\n",
    "df_normalized = df.copy()\n",
    "df_normalized['Tweet'] = df_normalized['Tweet'].apply(normalizeText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc1d1d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Gembira    473\n",
       "Marah      470\n",
       "Takut      424\n",
       "Cinta      400\n",
       "Sedih      341\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalized['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d051b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.to_csv('../data/external_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71394c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skripsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
